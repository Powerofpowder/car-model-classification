{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Построить классификатор изображений: определение модели автомобиля по фото.  ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport zipfile\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport csv\nimport sys\nimport os\nimport math\n\nfrom ImageDataAugmentor.image_data_augmentor import *\nimport albumentations\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, Callback, LearningRateScheduler\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications import EfficientNetB7\nimport efficientnet.keras as efn\nfrom tensorflow.keras.layers import *\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n\n# #увеличим дефолтный размер графиков\n# from pylab import rcParams\n# rcParams['figure.figsize'] = 10, 5\n# #графики в svg выглядят более четкими\n# %config InlineBackend.figure_format = 'svg' \n# %matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обновление tensorflow\n! pip install tensorflow==2.4.1\n# Загружаем обвязку под keras для использования продвинутых библиотек аугментации\n! pip install git+https://github.com/mjkvaak/ImageDataAugmentor\n#! pip freeze\n#! pip install efficientnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# В setup выносим основные настройки\n\nEPOCHS               = 5  # эпох на обучение\nBATCH_SIZE           = 48\nLR                   = 1e-4\nVAL_SPLIT            = 0.15 # выделяем на тест\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 224 # какого размера подаем изображения в сеть\nIMG_CHANNELS         = 3   # у RGB 3 канала\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nRANDOM_SEED=42\nDATA_PATH = '../input/sfcarclassif/'\nPATH = \"../working/car/\" # рабочая директория","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA / Анализ данных","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH+'train.csv')\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# распределение классов\ntrain_df.Category.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = PIL.Image.open(DATA_PATH+'train/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Подготовка данных\nАугментация данных","metadata":{}},{"cell_type":"code","source":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.LongestMaxSize(p=0.5),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n#     albumentations.MaskDropout(p=0.5),\n    albumentations.CLAHE(p=0.5),\n    albumentations.RandomBrightness(limit=0.2, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from ImageDataAugmentor.image_data_augmentor import *\n\ntrain_gen = ImageDataAugmentor(rescale=1./255,\n                        augment=AUGMENTATIONS, \n                        seed=RANDOM_SEED,\n                        validation_split=VAL_SPLIT\n                       )\n\ntrain_datagen = train_gen.flow_from_directory(DATA_PATH+'train/train', \n                                            class_mode='categorical', \n                                            batch_size=BATCH_SIZE, \n                                            target_size=(IMG_SIZE, IMG_SIZE),\n                                            shuffle=True,\n                                            subset='training'\n                                           )\ntest_datagen = train_gen.flow_from_directory(DATA_PATH+'train/train', \n                                             class_mode='categorical', \n                                             batch_size=BATCH_SIZE, \n                                             target_size=(IMG_SIZE, IMG_SIZE),\n                                             shuffle=True,\n                                             subset='validation'\n                                            )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# посмотрим на результат добавления измененных изображений\ntrain_datagen.show_data(rows=3, cols=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Модель","metadata":{}},{"cell_type":"code","source":"base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(base_model.layers))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# в качестве базы можно также взять архитектуру модели EfficientNetB5 (https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/EfficientNetB5)\n# base_model = efn.EfficientNetB5(weights='imagenet', \n#                                 include_top=False, \n#                                 input_shape = input_shape)\n# base_model = EfficientNetB7(include_top=False, weights='imagenet', input_shape = input_shape)\n# base_model = VGG16(weights='imagenet', include_top=False, input_shape = input_shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# поменять lr\n# LR=0.00001\n\n# Устанавливаем новую \"голову\" (head)\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.25)(x)\n# and a logistic layer -- let's say we have 10 classes\npredictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели\n\nДобавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель.","metadata":{}},{"cell_type":"code","source":"## настройка lr\n# def step_decay(epoch):\n#     initial_lrate = 0.1\n#     drop = 0.5\n#     epochs_drop = 10.0\n#     lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n#     return lrate\n\n# learning schedule callback\n# lrate = LearningRateScheduler(step_decay)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\ncallbacks_list = [\n    checkpoint,\n#     lrate,\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# callbacks_list = [\n#     tf.keras.callbacks.EarlyStopping(patience=2),\n#     tf.keras.callbacks.ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max'),\n#     tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n# #     lrate,\n# ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR), \n              metrics=[\"accuracy\"])\n\nhistory = model.fit(\n        train_datagen,\n        steps_per_epoch = train_datagen.samples//train_datagen.batch_size,\n        validation_data = test_datagen, \n        validation_steps = test_datagen.samples//test_datagen.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)\n\n#model.save('../working/model_step4.hdf5') \nmodel.load_weights('best_model.hdf5') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learn is an instance of Learner class or one of derived classes like ConvLearner\nmodel.lr_find()\nmodel.sched.plot_lr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model)\nmodel.save('../working/model_last.hdf5')\nmodel.load_weights('best_model.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate_generator(test_datagen, steps=len(test_datagen), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"base_model.trainable = True","metadata":{}},{"cell_type":"code","source":"base_model.trainable = True\n\n# Fine-tune from this layer onwards\nfine_tune_at = len(base_model.layers)//2\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR=0.0001\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR), \n              metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n        train_datagen,\n        steps_per_epoch = train_datagen.samples//train_datagen.batch_size,\n        validation_data = test_datagen, \n        validation_steps = test_datagen.samples//test_datagen.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scores = model.evaluate(test_datagen, verbose=1)\n# print(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save('../working/model_step2.hdf5')\nmodel.load_weights('best_model.hdf5') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Предсказание на тестовых данных","metadata":{}},{"cell_type":"code","source":"test_gen = ImageDataAugmentor(rescale=1./255)\ntest_sub_generator = test_gen.flow_from_dataframe(dataframe=sample_submission,\n                                            directory=DATA_PATH+'test/test_upload/',\n                                            x_col=\"Id\",\n                                            y_col=None,\n                                            shuffle=False,\n                                            class_mode=None,\n                                            target_size=(IMG_SIZE, IMG_SIZE),\n                                            batch_size=BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sub_generator.samples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sub_generator.reset()\npredictions = model.predict(test_sub_generator, \n                                      steps=len(test_sub_generator), \n                                      verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_datagen.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}